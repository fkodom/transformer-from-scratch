# transformer-from-scratch
Code for my Medium blog post: [Transformers from Scratch in PyTorch](https://medium.com/the-dl/transformers-from-scratch-in-pytorch-8777e346ca51)

**Note:**  This Transformer code does **not** include masked attention.  That was intentional, because it led to a much cleaner implementation.  This repository is intended for educational purposes only.  I believe that everything here is correct, but make no guarantees if for some reason you decide to use it in your own project.
